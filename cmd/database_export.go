/*
 * Copyright Metaplay. Licensed under the Apache-2.0 license.
 */

package cmd

import (
	"archive/zip"
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"regexp"
	"time"

	"github.com/metaplay/cli/pkg/envapi"
	"github.com/metaplay/cli/pkg/kubeutil"
	"github.com/metaplay/cli/pkg/styles"
	"github.com/rs/zerolog/log"
	"github.com/spf13/cobra"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/client-go/kubernetes/scheme"
)

// databaseExportOpts holds the options for the 'database export' command
type databaseExportOpts struct {
	UsePositionalArgs

	// Environment and output file
	argEnvironment string
	argOutputFile  string
}

func init() {
	o := databaseExportOpts{}

	args := o.Arguments()
	args.AddStringArgument(&o.argEnvironment, "ENVIRONMENT", "Target environment name or id, eg, 'lovely-wombats-build-nimbly'.")
	args.AddStringArgumentOpt(&o.argOutputFile, "OUTPUT_FILE", "Output file path for the database snapshot. Defaults to 'database-snapshot-${env}-${timestamp}.mdb' if not specified.")

	cmd := &cobra.Command{
		Use:     "export [ENVIRONMENT] [OUTPUT_FILE] [flags]",
		Aliases: []string{"exp"},
		Short:   "[preview] Export database snapshot from an environment",
		Long: renderLong(&o, `
			PREVIEW: This is a preview feature and interface may change in the future.

			Export a full database snapshot from the specified environment using mariadb-dump.

			DISCLAIMER: This operation is not a a real backup and is intended for ad hoc database
			exports only. This operation should only be used for relatively small databases as it
			copies the entire database to the machine running the CLI.

			The generated snapshot is a zip file containing metadata about the snapshot and a compressed
			SQL dump for each shard, generated by mariadb-dump. The format of the snapshot is subject
			to change in the future.

			This command starts a temporary debug pod and runs mariadb-dump inside it, connects
			to the read-only replica of each shard of the database and creates a complete snapshot.

			{Arguments}

			Related commands:
			- 'metaplay database import' imports a database snapshot into an environment.
			- 'metaplay debug database' connects to a database shard interactively.
		`),
		Example: renderExample(`
			# Export database from 'nimbly' environment (uses default filename)
			metaplay database export nimbly

			# Export database to a specific file
			metaplay database export nimbly my_database_snapshot.mdb
		`),
		Run: runCommand(&o),
	}
	databaseCmd.AddCommand(cmd)
}

func (o *databaseExportOpts) Prepare(cmd *cobra.Command, args []string) error {
	// Generate default output file if not specified
	if o.argOutputFile == "" {
		timestamp := time.Now().Format("20060102-150405")
		o.argOutputFile = fmt.Sprintf("database-snapshot-%s-%s.mdb", o.argEnvironment, timestamp)
	}
	return nil
}

func (o *databaseExportOpts) Run(cmd *cobra.Command) error {
	// Resolve the project & auth provider
	project, err := tryResolveProject()
	if err != nil {
		return err
	}

	// Resolve environment config
	envConfig, tokenSet, err := resolveEnvironment(cmd.Context(), project, o.argEnvironment)
	if err != nil {
		return err
	}

	// Resolve target environment & game server
	targetEnv := envapi.NewTargetEnvironment(tokenSet, envConfig.StackDomain, envConfig.HumanID)
	kubeCli, err := targetEnv.GetPrimaryKubeClient()
	if err != nil {
		return err
	}

	// Fetch the database shard configuration from Kubernetes secret
	log.Debug().Str("namespace", kubeCli.Namespace).Msg("Fetching database shard configuration")
	shards, err := kubeutil.FetchDatabaseShardsFromSecret(cmd.Context(), kubeCli, kubeCli.Namespace)
	if err != nil {
		return err
	}

	// Validate that we have at least one shard
	if len(shards) == 0 {
		return fmt.Errorf("no database shards found in environment")
	}

	// Fill in shard indices
	for shardNdx := range shards {
		shards[shardNdx].ShardIndex = shardNdx
	}

	// Show info
	log.Info().Msg("")
	log.Info().Msg("Database export info:")
	log.Info().Msgf("  Environment: %s", styles.RenderTechnical(o.argEnvironment))
	log.Info().Msgf("  Shards:      %s", styles.RenderTechnical(fmt.Sprintf("%d", len(shards))))
	log.Info().Msgf("  Output file: %s", styles.RenderTechnical(o.argOutputFile))
	log.Info().Msg("")

	// Create a debug container to run mariadb-dump
	log.Debug().Msg("Creating debug pod for database export")
	podName, cleanup, err := kubeutil.CreateDebugPod(
		cmd.Context(),
		kubeCli,
		debugDatabaseImage,
		false,
		false,
		[]string{"sleep", "3600"},
	)
	if err != nil {
		return err
	}
	log.Debug().Str("pod_name", podName).Msg("Debug pod created successfully")
	// Make sure the debug container is cleaned up even if we return early
	defer cleanup()

	// Export the database
	log.Debug().Str("output_file", o.argOutputFile).Msg("Start database export")
	return o.exportDatabaseContents(cmd.Context(), kubeCli, podName, "debug", shards)
}

// DatabaseSnapshotMetadata contains information about the database export
type DatabaseSnapshotMetadata struct {
	Version       int       `json:"version"`
	Environment   string    `json:"environment"`
	DatabaseName  string    `json:"database_name"`
	NumShards     int       `json:"num_shards"`
	ExportedAt    time.Time `json:"exported_at"`
	Compression   string    `json:"compression"`
	ExportOptions string    `json:"export_options"`
}

// Main function to export database contents - creates zip file, writes metadata, and exports all shards
func (o *databaseExportOpts) exportDatabaseContents(ctx context.Context, kubeCli *envapi.KubeClient, podName, debugContainerName string, shards []kubeutil.DatabaseShardConfig) error {
	log.Info().Msgf("Exporting database...")
	exportOptions := "--routines --triggers --no-tablespaces"

	// Create output zip file
	log.Debug().Str("zip_file", o.argOutputFile).Msg("Creating output zip file")
	zipFile, err := os.Create(o.argOutputFile)
	if err != nil {
		return fmt.Errorf("failed to create zip file: %v", err)
	}
	defer zipFile.Close()

	// Create zip writer
	zipWriter := zip.NewWriter(zipFile)
	defer zipWriter.Close()

	// Write metadata to zip
	log.Debug().Msg("Writing metadata to zip file")
	err = o.writeMetadataToZip(zipWriter, shards, exportOptions)
	if err != nil {
		return fmt.Errorf("failed to write metadata: %v", err)
	}

	// Extract schema from shard #0 first
	log.Debug().Msg("Extracting database schema from shard #0")
	schemaContent, err := o.extractDatabaseSchema(ctx, kubeCli, podName, debugContainerName, exportOptions, shards[0])
	if err != nil {
		return fmt.Errorf("failed to extract schema: %v", err)
	}

	// Apply schema fixups
	schemaContent = o.applySchemaFixups(schemaContent)

	// Write schema to zip file
	err = o.writeSchemaToZip(zipWriter, schemaContent)
	if err != nil {
		return fmt.Errorf("failed to write schema to zip: %v", err)
	}

	// Export data from each shard
	var shardFileNames []string
	for _, shard := range shards {
		log.Debug().Int("shard_index", shard.ShardIndex).Str("database_name", shard.DatabaseName).Msg("Starting shard data export")
		shardFileName, err := o.exportDatabaseShardData(ctx, zipWriter, kubeCli, podName, debugContainerName, shard)
		if err != nil {
			return fmt.Errorf("failed to export shard %d data: %v", shard.ShardIndex, err)
		}
		log.Debug().Int("shard_index", shard.ShardIndex).Str("shard_file", shardFileName).Msg("Shard data export completed")
		shardFileNames = append(shardFileNames, shardFileName)
	}

	log.Info().Msg("")
	log.Info().Msgf("âœ… Database export completed successfully")

	return nil
}

// Helper function to write metadata to zip file
func (o *databaseExportOpts) writeMetadataToZip(zipWriter *zip.Writer, shards []kubeutil.DatabaseShardConfig, exportOptions string) error {

	// Use first shard for database name (all shards should have same database name)
	databaseName := ""
	if len(shards) > 0 {
		databaseName = shards[0].DatabaseName
	}

	// Create metadata
	log.Debug().Str("database_name", databaseName).Int("num_shards", len(shards)).Msg("Creating export metadata")
	metadata := DatabaseSnapshotMetadata{
		Version:       1,
		Environment:   o.argEnvironment,
		DatabaseName:  databaseName,
		NumShards:     len(shards),
		ExportedAt:    time.Now().UTC(),
		Compression:   "gzip",
		ExportOptions: exportOptions,
	}

	// Create metadata JSON in memory
	metadataBytes, err := json.MarshalIndent(metadata, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal metadata: %v", err)
	}

	// Write metadata file to zip
	metadataFileName := "metadata.json"
	metadataHeader := &zip.FileHeader{
		Name:     metadataFileName,
		Method:   zip.Store, // No compression for small metadata file
		Modified: time.Now(),
	}
	metadataHeader.SetMode(0644)

	// Write metadata file to zip
	metadataWriter, err := zipWriter.CreateHeader(metadataHeader)
	if err != nil {
		return fmt.Errorf("failed to create metadata writer: %v", err)
	}
	if _, err := metadataWriter.Write(metadataBytes); err != nil {
		return fmt.Errorf("failed to write metadata content: %v", err)
	}

	return nil
}

// Helper function to extract database schema from shard #0 into memory
func (o *databaseExportOpts) extractDatabaseSchema(ctx context.Context, kubeCli *envapi.KubeClient, podName, debugContainerName, exportOptions string, shard kubeutil.DatabaseShardConfig) (string, error) {
	// Build mariadb-dump command for schema only (DDL) - no gzip compression for in-memory processing
	schemaCmd := fmt.Sprintf("mariadb-dump -h %s -u %s -p%s --no-create-db --no-data %s %s",
		shard.ReadOnlyHost, // Use read-only replica
		shard.UserId,
		shard.Password,
		exportOptions,
		shard.DatabaseName)
	log.Debug().Str("host", shard.ReadOnlyHost).Str("database", shard.DatabaseName).Msg("Executing schema dump command")

	// Capture output in memory buffer
	var schemaBuffer bytes.Buffer

	// Execute schema dump command
	req := kubeCli.Clientset.CoreV1().
		RESTClient().
		Post().
		Resource("pods").
		Name(podName).
		Namespace(kubeCli.Namespace).
		SubResource("exec").
		VersionedParams(&corev1.PodExecOptions{
			Container: debugContainerName,
			Command:   []string{"/bin/sh", "-c", schemaCmd},
			Stdin:     false,
			Stdout:    true,
			Stderr:    true,
			TTY:       false,
		}, scheme.ParameterCodec)

	ioStreams := IOStreams{
		In:     nil,
		Out:    &schemaBuffer, // Capture to memory buffer
		ErrOut: os.Stderr,
	}

	err := execRemoteKubernetesCommand(ctx, kubeCli.RestConfig, req.URL(), ioStreams, false, false)
	if err != nil {
		return "", fmt.Errorf("schema extraction failed: %v", err)
	}

	schemaContent := schemaBuffer.String()
	log.Debug().Int("schema_size", len(schemaContent)).Msg("Schema extracted to memory successfully")

	return schemaContent, nil
}

// Helper function to apply schema modifications and fixups
func (o *databaseExportOpts) applySchemaFixups(schemaContent string) string {
	log.Debug().Msgf("Original schema from mariadb-dump:\n%s", schemaContent)

	// Ensure all tables use utf8mb4_bin collation
	schemaContent = o.enforceUtf8mb4BinCollation(schemaContent)

	log.Debug().Msg("Applied schema fixups")
	return schemaContent
}

// Helper function to enforce utf8mb4_bin collation on all tables
func (o *databaseExportOpts) enforceUtf8mb4BinCollation(schemaContent string) string {
	// Simple approach: replace all collation references with utf8mb4_bin

	// 1. Replace table-level collation in CREATE TABLE statements
	tableCollationPattern := regexp.MustCompile(`(?i)DEFAULT\s+CHARSET=\w+\s+COLLATE=\w+`)
	result := tableCollationPattern.ReplaceAllString(schemaContent, "DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin")

	// 2. Replace column-level collation specifications
	columnCollationPattern := regexp.MustCompile(`(?i)CHARACTER\s+SET\s+\w+\s+COLLATE\s+\w+`)
	result = columnCollationPattern.ReplaceAllString(result, "CHARACTER SET utf8mb4 COLLATE utf8mb4_bin")

	// 3. Replace standalone COLLATE clauses
	standaloneCollatePattern := regexp.MustCompile(`(?i)COLLATE\s+\w+`)
	result = standaloneCollatePattern.ReplaceAllString(result, "COLLATE utf8mb4_bin")

	// 4. Replace standalone CHARSET clauses
	standaloneCharsetPattern := regexp.MustCompile(`(?i)CHARSET=\w+`)
	result = standaloneCharsetPattern.ReplaceAllString(result, "CHARSET=utf8mb4")

	log.Debug().Msg("Enforced utf8mb4_bin collation on all tables and columns")
	return result
}

// Helper function to write schema content to zip file
func (o *databaseExportOpts) writeSchemaToZip(zipWriter *zip.Writer, schemaContent string) error {
	// Prepare zip header for schema file
	schemaHeader := &zip.FileHeader{
		Name:     "schema.sql",
		Method:   zip.Deflate, // Use compression since we're not pre-compressing
		Modified: time.Now(),
	}
	schemaHeader.SetMode(0644)

	// Create zip writer for schema file
	schemaWriter, err := zipWriter.CreateHeader(schemaHeader)
	if err != nil {
		return fmt.Errorf("failed to create schema writer: %v", err)
	}

	// Write schema content to zip
	_, err = schemaWriter.Write([]byte(schemaContent))
	if err != nil {
		return fmt.Errorf("failed to write schema content: %v", err)
	}

	log.Debug().Msg("Schema written to schema.sql in zip archive")
	return nil
}

// Helper function to export data only from a single database shard
func (o *databaseExportOpts) exportDatabaseShardData(ctx context.Context, zipWriter *zip.Writer, kubeCli *envapi.KubeClient, podName, debugContainerName string, shard kubeutil.DatabaseShardConfig) (string, error) {
	// Build mariadb-dump command for data only (DML)
	dataCmd := fmt.Sprintf("mariadb-dump -h %s -u %s -p%s --no-create-info --no-tablespaces --single-transaction --skip-triggers %s | gzip",
		shard.ReadOnlyHost, // Use read-only replica
		shard.UserId,
		shard.Password,
		shard.DatabaseName)
	log.Debug().Str("host", shard.ReadOnlyHost).Str("database", shard.DatabaseName).Msg("Executing data dump command")

	// Prepare zip header for streaming
	snapshotFileName := fmt.Sprintf("shard_%d.sql.gz", shard.ShardIndex)
	shardHeader := &zip.FileHeader{
		Name:     snapshotFileName,
		Method:   zip.Store, // Use Store since data is already gzipped
		Modified: time.Now(),
	}
	shardHeader.SetMode(0644)

	// Create zip writer for this file - stream directly without buffering
	shardFileWriter, err := zipWriter.CreateHeader(shardHeader)
	if err != nil {
		return "", fmt.Errorf("failed to create zip writer: %v", err)
	}

	// Execute mariadb-dump command and stream output directly to zip
	req := kubeCli.Clientset.CoreV1().
		RESTClient().
		Post().
		Resource("pods").
		Name(podName).
		Namespace(kubeCli.Namespace).
		SubResource("exec").
		VersionedParams(&corev1.PodExecOptions{
			Container: debugContainerName,
			Command:   []string{"/bin/sh", "-c", dataCmd},
			Stdin:     false,
			Stdout:    true,
			Stderr:    true,
			TTY:       false,
		}, scheme.ParameterCodec)

	ioStreams := IOStreams{
		In:     nil,
		Out:    shardFileWriter, // Stream directly to zip writer
		ErrOut: os.Stderr,
	}

	err = execRemoteKubernetesCommand(ctx, kubeCli.RestConfig, req.URL(), ioStreams, false, false)
	if err != nil {
		return "", fmt.Errorf("data export failed: %v", err)
	}
	log.Debug().Str("file", snapshotFileName).Msg("Shard data streamed directly to zip archive")

	return snapshotFileName, nil
}
